# ClappEchoesFinal

A Pen created on CodePen.io. Original URL: [https://codepen.io/marukowanzi/pen/pomxrpw](https://codepen.io/marukowanzi/pen/pomxrpw).

Uses the "Drums RNN" pretrained model from Google Magenta https://github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn

Running on Magenta.js, TensorFlow.js and Tone.js

The arduino is connected to custom made clapping machine which can play "rhythm duet" with you. The machine uses one NEMA 17 (1.5A 3.8V) connected to pwm pin3.

Research Questions:
1) HOW CAN AI COMMUNICATE WITH HUMAN IN A MULTI-PERCEPTIONAL WAY?
Robots that can play, interact, communicate, collaborate with human. Our doubt is, Does AI only communicate with human through text, like chat GPT？Can we build an AI that use other perceptions like sounds, actions, images, haptics to communicate? In our project, it is sound.
2)  HOW BODY BECOME AN INSTRUMENT AND A MEDIUM OF SOCIAL INTERACTION?

It is a potential that we can use our body as multiple “instruments”, and also a medium to interact with AI, and AI will response you with similar or different actions. This transforms physical actions into an interactive musical experience. So, it creates a “soundscape” .  

Interaction Process: You are playing a “rhythm duet” with AI, when you clap your hands as a rhythm input, the AI will respond you with a similar (but not the same) rhythm by clapping “its” hands. 